{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the directories where your modules and files are\n",
    "modules_path = 'C:\\\\Users\\loren\\Documents\\Progetti\\__repo__\\_Modules_LF95'\n",
    "files_path = 'C:\\\\Users\\loren\\Documents\\Progetti\\Scuola\\DataMining_Advanced\\_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moduli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available files for the project:\n",
      "['dataset.csv', 'datatest.txt', 'datatest2.txt', 'datatraining.txt', 'test1.csv', 'test2.csv', 'training.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if os.path.isdir(modules_path) and (modules_path not in sys.path):\n",
    "    sys.path.append(modules_path)\n",
    "\n",
    "files_list = os.listdir(files_path)\n",
    "print('available files for the project:', files_list, sep='\\n')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from data_science.preprocessing import df_handle\n",
    "from data_science.preprocessing import data_understanding\n",
    "from data_science.preprocessing import data_preparation\n",
    "from data_science.evaluation import supervised_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creiamo un validation set con il 30% del training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1, X_val, temp2, y_val = df_handle.ml_setup(trainFile_name='training.csv', y_name='Occupancy', test_portion=0.3,\n",
    "                                                    search_in_folder=files_path, date_col_name='date')\n",
    "del temp1, temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importiamo training e test veri e propri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_handle.ml_setup(trainFile_name='training.csv', y_name='Occupancy',\n",
    "                                                      testFile_name='test1.csv', search_in_folder=files_path,\n",
    "                                                      date_col_name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:51:00</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.250000</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:52:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:53:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.500000</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:54:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.250000</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:55:00</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.500000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:29:00</th>\n",
       "      <td>21.05</td>\n",
       "      <td>36.0975</td>\n",
       "      <td>433.0</td>\n",
       "      <td>787.250000</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:30:00</th>\n",
       "      <td>21.05</td>\n",
       "      <td>35.9950</td>\n",
       "      <td>433.0</td>\n",
       "      <td>789.500000</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:31:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.0950</td>\n",
       "      <td>433.0</td>\n",
       "      <td>798.500000</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:32:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2600</td>\n",
       "      <td>433.0</td>\n",
       "      <td>820.333333</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:33:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2000</td>\n",
       "      <td>447.0</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8143 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Temperature  Humidity  Light         CO2  HumidityRatio  \\\n",
       "date                                                                           \n",
       "2015-02-04 17:51:00        23.18   27.2720  426.0  721.250000       0.004793   \n",
       "2015-02-04 17:52:00        23.15   27.2675  429.5  714.000000       0.004783   \n",
       "2015-02-04 17:53:00        23.15   27.2450  426.0  713.500000       0.004779   \n",
       "2015-02-04 17:54:00        23.15   27.2000  426.0  708.250000       0.004772   \n",
       "2015-02-04 17:55:00        23.10   27.2000  426.0  704.500000       0.004757   \n",
       "...                          ...       ...    ...         ...            ...   \n",
       "2015-02-10 09:29:00        21.05   36.0975  433.0  787.250000       0.005579   \n",
       "2015-02-10 09:30:00        21.05   35.9950  433.0  789.500000       0.005563   \n",
       "2015-02-10 09:31:00        21.10   36.0950  433.0  798.500000       0.005596   \n",
       "2015-02-10 09:32:00        21.10   36.2600  433.0  820.333333       0.005621   \n",
       "2015-02-10 09:33:00        21.10   36.2000  447.0  821.000000       0.005612   \n",
       "\n",
       "                     year  month  day  hour  minute  second  \n",
       "date                                                         \n",
       "2015-02-04 17:51:00  2015      2    4    17      51       0  \n",
       "2015-02-04 17:52:00  2015      2    4    17      52       0  \n",
       "2015-02-04 17:53:00  2015      2    4    17      53       0  \n",
       "2015-02-04 17:54:00  2015      2    4    17      54       0  \n",
       "2015-02-04 17:55:00  2015      2    4    17      55       0  \n",
       "...                   ...    ...  ...   ...     ...     ...  \n",
       "2015-02-10 09:29:00  2015      2   10     9      29       0  \n",
       "2015-02-10 09:30:00  2015      2   10     9      30       0  \n",
       "2015-02-10 09:31:00  2015      2   10     9      31       0  \n",
       "2015-02-10 09:32:00  2015      2   10     9      32       0  \n",
       "2015-02-10 09:33:00  2015      2   10     9      33       0  \n",
       "\n",
       "[8143 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del X_train['year'], X_train['month'], X_train['minute'], X_train['second'], X_train['day'], X_train['HumidityRatio'], X_train['Light']\n",
    "del X_test['year'], X_test['month'], X_test['minute'], X_test['second'], X_test['day'], X_test['HumidityRatio'], X_test['Light']\n",
    "del X_val['year'], X_val['month'], X_val['minute'], X_val['second'], X_val['day'], X_val['HumidityRatio'], X_val['Light']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>CO2</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:51:00</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>721.250000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:52:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:53:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>713.500000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:54:00</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>708.250000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:55:00</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>704.500000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:29:00</th>\n",
       "      <td>21.05</td>\n",
       "      <td>36.0975</td>\n",
       "      <td>787.250000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:30:00</th>\n",
       "      <td>21.05</td>\n",
       "      <td>35.9950</td>\n",
       "      <td>789.500000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:31:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.0950</td>\n",
       "      <td>798.500000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:32:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2600</td>\n",
       "      <td>820.333333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10 09:33:00</th>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2000</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8143 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Temperature  Humidity         CO2  hour\n",
       "date                                                        \n",
       "2015-02-04 17:51:00        23.18   27.2720  721.250000    17\n",
       "2015-02-04 17:52:00        23.15   27.2675  714.000000    17\n",
       "2015-02-04 17:53:00        23.15   27.2450  713.500000    17\n",
       "2015-02-04 17:54:00        23.15   27.2000  708.250000    17\n",
       "2015-02-04 17:55:00        23.10   27.2000  704.500000    17\n",
       "...                          ...       ...         ...   ...\n",
       "2015-02-10 09:29:00        21.05   36.0975  787.250000     9\n",
       "2015-02-10 09:30:00        21.05   35.9950  789.500000     9\n",
       "2015-02-10 09:31:00        21.10   36.0950  798.500000     9\n",
       "2015-02-10 09:32:00        21.10   36.2600  820.333333     9\n",
       "2015-02-10 09:33:00        21.10   36.2000  821.000000     9\n",
       "\n",
       "[8143 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "X_val = np.array(X_val).reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8143, 1, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\Multivariate LSTM Classifier\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(2, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(2, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8143, 1, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. TimeSteps:  1\n",
      "N. Output Labels:  2\n",
      "N. Features:  4\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2]\n",
    "print(\"N. TimeSteps: \", n_timesteps)\n",
    "print(\"N. Output Labels: \", n_outputs)\n",
    "print(\"N. Features: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "lstm = build_lstm(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 2)              56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 2)              8         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 2)              40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 2)              8         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 2)              40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 2)              8         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                4480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 100,034\n",
      "Trainable params: 98,742\n",
      "Non-trainable params: 1,292\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 50\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\loren\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8143 samples, validate on 2443 samples\n",
      "Epoch 1/100\n",
      "8143/8143 [==============================] - 6s 707us/step - loss: 0.4165 - accuracy: 0.8628 - val_loss: 0.5176 - val_accuracy: 0.7876\n",
      "Epoch 2/100\n",
      "8143/8143 [==============================] - 2s 258us/step - loss: 0.2767 - accuracy: 0.8979 - val_loss: 0.5727 - val_accuracy: 0.7876\n",
      "Epoch 3/100\n",
      "8143/8143 [==============================] - 2s 243us/step - loss: 0.2700 - accuracy: 0.8982 - val_loss: 0.6027 - val_accuracy: 0.7876\n",
      "Epoch 4/100\n",
      "8143/8143 [==============================] - 2s 237us/step - loss: 0.2593 - accuracy: 0.9019 - val_loss: 0.2664 - val_accuracy: 0.7876\n",
      "Epoch 5/100\n",
      "8143/8143 [==============================] - 2s 237us/step - loss: 0.2485 - accuracy: 0.9074 - val_loss: 0.5838 - val_accuracy: 0.8240\n",
      "Epoch 6/100\n",
      "8143/8143 [==============================] - 2s 232us/step - loss: 0.2599 - accuracy: 0.8982 - val_loss: 0.2474 - val_accuracy: 0.9198\n",
      "Epoch 7/100\n",
      "8143/8143 [==============================] - 2s 246us/step - loss: 0.2421 - accuracy: 0.9080 - val_loss: 0.2737 - val_accuracy: 0.9165\n",
      "Epoch 8/100\n",
      "8143/8143 [==============================] - 2s 256us/step - loss: 0.2411 - accuracy: 0.9086 - val_loss: 0.3249 - val_accuracy: 0.9116\n",
      "Epoch 9/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2349 - accuracy: 0.9116 - val_loss: 0.8112 - val_accuracy: 0.8702\n",
      "Epoch 10/100\n",
      "8143/8143 [==============================] - 2s 217us/step - loss: 0.2392 - accuracy: 0.9078 - val_loss: 0.2150 - val_accuracy: 0.9222\n",
      "Epoch 11/100\n",
      "8143/8143 [==============================] - 2s 221us/step - loss: 0.2405 - accuracy: 0.9086 - val_loss: 0.1834 - val_accuracy: 0.9325\n",
      "Epoch 12/100\n",
      "8143/8143 [==============================] - 2s 218us/step - loss: 0.2390 - accuracy: 0.9119 - val_loss: 0.4596 - val_accuracy: 0.8723\n",
      "Epoch 13/100\n",
      "8143/8143 [==============================] - 2s 241us/step - loss: 0.2371 - accuracy: 0.9095 - val_loss: 0.1830 - val_accuracy: 0.9321\n",
      "Epoch 14/100\n",
      "8143/8143 [==============================] - 2s 248us/step - loss: 0.2442 - accuracy: 0.9059 - val_loss: 1.1383 - val_accuracy: 0.2124\n",
      "Epoch 15/100\n",
      "8143/8143 [==============================] - 2s 254us/step - loss: 0.2371 - accuracy: 0.9105 - val_loss: 0.1867 - val_accuracy: 0.9226\n",
      "Epoch 16/100\n",
      "8143/8143 [==============================] - 2s 239us/step - loss: 0.2353 - accuracy: 0.9117 - val_loss: 0.3277 - val_accuracy: 0.9001\n",
      "Epoch 17/100\n",
      "8143/8143 [==============================] - 2s 223us/step - loss: 0.2313 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9312\n",
      "Epoch 18/100\n",
      "8143/8143 [==============================] - 2s 250us/step - loss: 0.2348 - accuracy: 0.9092 - val_loss: 0.3351 - val_accuracy: 0.9218\n",
      "Epoch 19/100\n",
      "8143/8143 [==============================] - 2s 240us/step - loss: 0.2494 - accuracy: 0.9010 - val_loss: 0.1986 - val_accuracy: 0.9296\n",
      "Epoch 20/100\n",
      "8143/8143 [==============================] - 2s 242us/step - loss: 0.2360 - accuracy: 0.9096 - val_loss: 0.1899 - val_accuracy: 0.9243\n",
      "Epoch 21/100\n",
      "8143/8143 [==============================] - 2s 223us/step - loss: 0.2389 - accuracy: 0.9075 - val_loss: 0.2001 - val_accuracy: 0.9226\n",
      "Epoch 22/100\n",
      "8143/8143 [==============================] - 2s 237us/step - loss: 0.2324 - accuracy: 0.9074 - val_loss: 0.1926 - val_accuracy: 0.9321\n",
      "Epoch 23/100\n",
      "8143/8143 [==============================] - 2s 265us/step - loss: 0.2332 - accuracy: 0.9063 - val_loss: 0.1952 - val_accuracy: 0.9235\n",
      "Epoch 24/100\n",
      "8143/8143 [==============================] - 2s 257us/step - loss: 0.2355 - accuracy: 0.9112 - val_loss: 0.1844 - val_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "8143/8143 [==============================] - 2s 209us/step - loss: 0.2278 - accuracy: 0.9142 - val_loss: 0.3152 - val_accuracy: 0.8436\n",
      "Epoch 26/100\n",
      "8143/8143 [==============================] - 2s 233us/step - loss: 0.2256 - accuracy: 0.9117 - val_loss: 0.2259 - val_accuracy: 0.9271\n",
      "Epoch 27/100\n",
      "8143/8143 [==============================] - 2s 210us/step - loss: 0.2262 - accuracy: 0.9135 - val_loss: 0.1845 - val_accuracy: 0.9247\n",
      "Epoch 28/100\n",
      "8143/8143 [==============================] - 2s 205us/step - loss: 0.2290 - accuracy: 0.9100 - val_loss: 0.2060 - val_accuracy: 0.9194\n",
      "Epoch 29/100\n",
      "8143/8143 [==============================] - 2s 198us/step - loss: 0.2363 - accuracy: 0.9100 - val_loss: 0.1904 - val_accuracy: 0.9222\n",
      "Epoch 30/100\n",
      "8143/8143 [==============================] - 2s 218us/step - loss: 0.2334 - accuracy: 0.9110 - val_loss: 0.2360 - val_accuracy: 0.9288\n",
      "Epoch 31/100\n",
      "8143/8143 [==============================] - 2s 219us/step - loss: 0.2308 - accuracy: 0.9111 - val_loss: 0.3646 - val_accuracy: 0.7990\n",
      "Epoch 32/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2331 - accuracy: 0.9092 - val_loss: 0.2774 - val_accuracy: 0.9161\n",
      "Epoch 33/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2308 - accuracy: 0.9126 - val_loss: 0.1832 - val_accuracy: 0.9275\n",
      "Epoch 34/100\n",
      "8143/8143 [==============================] - 2s 209us/step - loss: 0.2341 - accuracy: 0.9104 - val_loss: 0.1823 - val_accuracy: 0.9316\n",
      "Epoch 35/100\n",
      "8143/8143 [==============================] - 2s 212us/step - loss: 0.2326 - accuracy: 0.9108 - val_loss: 0.2378 - val_accuracy: 0.9161\n",
      "Epoch 36/100\n",
      "8143/8143 [==============================] - 2s 214us/step - loss: 0.2377 - accuracy: 0.9111 - val_loss: 0.4141 - val_accuracy: 0.8297\n",
      "Epoch 37/100\n",
      "8143/8143 [==============================] - 2s 205us/step - loss: 0.2318 - accuracy: 0.9144 - val_loss: 0.2204 - val_accuracy: 0.9267\n",
      "Epoch 38/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2269 - accuracy: 0.9126 - val_loss: 0.1945 - val_accuracy: 0.9247\n",
      "Epoch 39/100\n",
      "8143/8143 [==============================] - 2s 199us/step - loss: 0.2356 - accuracy: 0.9091 - val_loss: 0.2576 - val_accuracy: 0.9226\n",
      "Epoch 40/100\n",
      "8143/8143 [==============================] - 2s 203us/step - loss: 0.2229 - accuracy: 0.9133 - val_loss: 0.1824 - val_accuracy: 0.9296\n",
      "Epoch 41/100\n",
      "8143/8143 [==============================] - 2s 214us/step - loss: 0.2295 - accuracy: 0.9101 - val_loss: 0.2739 - val_accuracy: 0.9161\n",
      "Epoch 42/100\n",
      "8143/8143 [==============================] - 2s 219us/step - loss: 0.2268 - accuracy: 0.9134 - val_loss: 0.1844 - val_accuracy: 0.9304\n",
      "Epoch 43/100\n",
      "8143/8143 [==============================] - 2s 208us/step - loss: 0.2356 - accuracy: 0.9139 - val_loss: 0.2265 - val_accuracy: 0.9329\n",
      "Epoch 44/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2341 - accuracy: 0.9102 - val_loss: 0.2918 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2296 - accuracy: 0.9106 - val_loss: 0.3282 - val_accuracy: 0.9194\n",
      "Epoch 46/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2367 - accuracy: 0.9092 - val_loss: 0.2681 - val_accuracy: 0.9218\n",
      "Epoch 47/100\n",
      "8143/8143 [==============================] - 2s 210us/step - loss: 0.2288 - accuracy: 0.9104 - val_loss: 0.2358 - val_accuracy: 0.9226\n",
      "Epoch 48/100\n",
      "8143/8143 [==============================] - 2s 208us/step - loss: 0.2319 - accuracy: 0.9113 - val_loss: 0.6100 - val_accuracy: 0.5952\n",
      "Epoch 49/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2303 - accuracy: 0.9094 - val_loss: 0.1909 - val_accuracy: 0.9263\n",
      "Epoch 50/100\n",
      "8143/8143 [==============================] - 2s 208us/step - loss: 0.2362 - accuracy: 0.9088 - val_loss: 0.4554 - val_accuracy: 0.7503\n",
      "Epoch 51/100\n",
      "8143/8143 [==============================] - 2s 210us/step - loss: 0.2328 - accuracy: 0.9072 - val_loss: 0.3278 - val_accuracy: 0.9173\n",
      "Epoch 52/100\n",
      "8143/8143 [==============================] - 2s 210us/step - loss: 0.2324 - accuracy: 0.9108 - val_loss: 0.2986 - val_accuracy: 0.9181\n",
      "Epoch 53/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2302 - accuracy: 0.9117 - val_loss: 0.6256 - val_accuracy: 0.5956\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8143/8143 [==============================] - 2s 203us/step - loss: 0.2300 - accuracy: 0.9097 - val_loss: 0.2360 - val_accuracy: 0.9173\n",
      "Epoch 55/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2274 - accuracy: 0.9135 - val_loss: 0.2257 - val_accuracy: 0.9194\n",
      "Epoch 56/100\n",
      "8143/8143 [==============================] - 2s 218us/step - loss: 0.2235 - accuracy: 0.9158 - val_loss: 0.1890 - val_accuracy: 0.9222\n",
      "Epoch 57/100\n",
      "8143/8143 [==============================] - 2s 208us/step - loss: 0.2245 - accuracy: 0.9121 - val_loss: 0.9916 - val_accuracy: 0.3054\n",
      "Epoch 58/100\n",
      "8143/8143 [==============================] - 2s 206us/step - loss: 0.2292 - accuracy: 0.9089 - val_loss: 0.6049 - val_accuracy: 0.5907\n",
      "Epoch 59/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2278 - accuracy: 0.9104 - val_loss: 0.3010 - val_accuracy: 0.9161\n",
      "Epoch 60/100\n",
      "8143/8143 [==============================] - 2s 212us/step - loss: 0.2323 - accuracy: 0.9107 - val_loss: 0.2010 - val_accuracy: 0.9218\n",
      "Epoch 61/100\n",
      "8143/8143 [==============================] - 2s 206us/step - loss: 0.2337 - accuracy: 0.9116 - val_loss: 0.2487 - val_accuracy: 0.9173\n",
      "Epoch 62/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2310 - accuracy: 0.9119 - val_loss: 0.6136 - val_accuracy: 0.5849\n",
      "Epoch 63/100\n",
      "8143/8143 [==============================] - 2s 238us/step - loss: 0.2315 - accuracy: 0.9117 - val_loss: 0.2718 - val_accuracy: 0.9194\n",
      "Epoch 64/100\n",
      "8143/8143 [==============================] - 2s 241us/step - loss: 0.2368 - accuracy: 0.9056 - val_loss: 0.4843 - val_accuracy: 0.6623\n",
      "Epoch 65/100\n",
      "8143/8143 [==============================] - 2s 266us/step - loss: 0.2266 - accuracy: 0.9132 - val_loss: 0.2164 - val_accuracy: 0.9288\n",
      "Epoch 66/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2273 - accuracy: 0.9121 - val_loss: 0.2007 - val_accuracy: 0.9267\n",
      "Epoch 67/100\n",
      "8143/8143 [==============================] - 2s 214us/step - loss: 0.2301 - accuracy: 0.9123 - val_loss: 0.2143 - val_accuracy: 0.9239\n",
      "Epoch 68/100\n",
      "8143/8143 [==============================] - 2s 215us/step - loss: 0.2296 - accuracy: 0.9126 - val_loss: 0.1831 - val_accuracy: 0.9267\n",
      "Epoch 69/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2269 - accuracy: 0.9159 - val_loss: 0.2183 - val_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "8143/8143 [==============================] - 2s 209us/step - loss: 0.2347 - accuracy: 0.9059 - val_loss: 0.3520 - val_accuracy: 0.8801\n",
      "Epoch 71/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2299 - accuracy: 0.9077 - val_loss: 0.1854 - val_accuracy: 0.9284\n",
      "Epoch 72/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2251 - accuracy: 0.9126 - val_loss: 0.2057 - val_accuracy: 0.9271\n",
      "Epoch 73/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2315 - accuracy: 0.9094 - val_loss: 0.7783 - val_accuracy: 0.4458\n",
      "Epoch 74/100\n",
      "8143/8143 [==============================] - 2s 200us/step - loss: 0.2373 - accuracy: 0.9059 - val_loss: 0.1867 - val_accuracy: 0.9271\n",
      "Epoch 75/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2271 - accuracy: 0.9159 - val_loss: 1.4623 - val_accuracy: 0.8183\n",
      "Epoch 76/100\n",
      "8143/8143 [==============================] - 2s 203us/step - loss: 0.2270 - accuracy: 0.9148 - val_loss: 0.2285 - val_accuracy: 0.9181\n",
      "Epoch 77/100\n",
      "8143/8143 [==============================] - 2s 210us/step - loss: 0.2246 - accuracy: 0.9134 - val_loss: 0.2446 - val_accuracy: 0.9210\n",
      "Epoch 78/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2247 - accuracy: 0.9153 - val_loss: 0.1891 - val_accuracy: 0.9292\n",
      "Epoch 79/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2301 - accuracy: 0.9127 - val_loss: 0.1869 - val_accuracy: 0.9247\n",
      "Epoch 80/100\n",
      "8143/8143 [==============================] - 2s 203us/step - loss: 0.2279 - accuracy: 0.9112 - val_loss: 0.2632 - val_accuracy: 0.9128\n",
      "Epoch 81/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2234 - accuracy: 0.9134 - val_loss: 0.2238 - val_accuracy: 0.9222\n",
      "Epoch 82/100\n",
      "8143/8143 [==============================] - 2s 209us/step - loss: 0.2296 - accuracy: 0.9139 - val_loss: 0.1927 - val_accuracy: 0.9304\n",
      "Epoch 83/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2249 - accuracy: 0.9158 - val_loss: 1.6759 - val_accuracy: 0.8133\n",
      "Epoch 84/100\n",
      "8143/8143 [==============================] - 2s 198us/step - loss: 0.2175 - accuracy: 0.9156 - val_loss: 0.1826 - val_accuracy: 0.9292\n",
      "Epoch 85/100\n",
      "8143/8143 [==============================] - 2s 205us/step - loss: 0.2253 - accuracy: 0.9132 - val_loss: 0.1914 - val_accuracy: 0.9321\n",
      "Epoch 86/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2209 - accuracy: 0.9162 - val_loss: 0.2004 - val_accuracy: 0.9321\n",
      "Epoch 87/100\n",
      "8143/8143 [==============================] - 2s 212us/step - loss: 0.2257 - accuracy: 0.9117 - val_loss: 0.1892 - val_accuracy: 0.9300\n",
      "Epoch 88/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2257 - accuracy: 0.9159 - val_loss: 0.1958 - val_accuracy: 0.9271\n",
      "Epoch 89/100\n",
      "8143/8143 [==============================] - 2s 214us/step - loss: 0.2280 - accuracy: 0.9110 - val_loss: 0.5011 - val_accuracy: 0.6758\n",
      "Epoch 90/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2236 - accuracy: 0.9142 - val_loss: 0.1905 - val_accuracy: 0.9296\n",
      "Epoch 91/100\n",
      "8143/8143 [==============================] - 2s 211us/step - loss: 0.2250 - accuracy: 0.9129 - val_loss: 0.3463 - val_accuracy: 0.9185\n",
      "Epoch 92/100\n",
      "8143/8143 [==============================] - 2s 213us/step - loss: 0.2250 - accuracy: 0.9127 - val_loss: 0.1866 - val_accuracy: 0.9275\n",
      "Epoch 93/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2264 - accuracy: 0.9132 - val_loss: 0.2654 - val_accuracy: 0.8985\n",
      "Epoch 94/100\n",
      "8143/8143 [==============================] - 2s 207us/step - loss: 0.2259 - accuracy: 0.9139 - val_loss: 0.7137 - val_accuracy: 0.8682\n",
      "Epoch 95/100\n",
      "8143/8143 [==============================] - 2s 199us/step - loss: 0.2323 - accuracy: 0.9107 - val_loss: 0.2233 - val_accuracy: 0.9280\n",
      "Epoch 96/100\n",
      "8143/8143 [==============================] - 2s 198us/step - loss: 0.2302 - accuracy: 0.9145 - val_loss: 0.2082 - val_accuracy: 0.9210\n",
      "Epoch 97/100\n",
      "8143/8143 [==============================] - 2s 198us/step - loss: 0.2257 - accuracy: 0.9148 - val_loss: 0.1880 - val_accuracy: 0.9263\n",
      "Epoch 98/100\n",
      "8143/8143 [==============================] - 2s 198us/step - loss: 0.2261 - accuracy: 0.9144 - val_loss: 0.1881 - val_accuracy: 0.9308\n",
      "Epoch 99/100\n",
      "8143/8143 [==============================] - 2s 200us/step - loss: 0.2263 - accuracy: 0.9124 - val_loss: 0.2114 - val_accuracy: 0.9337\n",
      "Epoch 100/100\n",
      "8143/8143 [==============================] - 2s 204us/step - loss: 0.2263 - accuracy: 0.9148 - val_loss: 0.2795 - val_accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "history_lstm = lstm.fit(X_train, y_train, epochs=100, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                       validation_data=(X_val, y_val)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8964352720450282\n",
      "\n",
      "F1-score: [0.91676719 0.86295929]\n",
      "\n",
      "Weighted Average F1-score: 0.8971419424590222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1693\n",
      "           1       0.83      0.89      0.86       972\n",
      "\n",
      "    accuracy                           0.90      2665\n",
      "   macro avg       0.89      0.90      0.89      2665\n",
      "weighted avg       0.90      0.90      0.90      2665\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy: %s' % supervised_evaluation.accuracy_score(y_test, y_pred), end='\\n\\n')\n",
    "print('F1-score: %s' % supervised_evaluation.f1_score(y_test, y_pred, average=None), end='\\n\\n')\n",
    "print('Weighted Average F1-score: %s' % supervised_evaluation.f1_score(y_test, y_pred, average='weighted'), end='\\n\\n')\n",
    "print(supervised_evaluation.classification_report(y_test, y_pred), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665/2665 [==============================] - 0s 85us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37738580138961597, 0.8964352607727051]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_handle.ml_setup(trainFile_name='training.csv', y_name='Occupancy',\n",
    "                                                      testFile_name='test2.csv', search_in_folder=files_path,\n",
    "                                                      date_col_name='date')\n",
    "\n",
    "del X_test['year'], X_test['month'], X_test['minute'], X_test['second'], X_test['day'], X_test['HumidityRatio'], X_test['Light']\n",
    "\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6910377358490566\n",
      "\n",
      "F1-score: [0.78234487 0.46776188]\n",
      "\n",
      "Weighted Average F1-score: 0.716247601010656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78      7703\n",
      "           1       0.37      0.65      0.47      2049\n",
      "\n",
      "    accuracy                           0.69      9752\n",
      "   macro avg       0.62      0.67      0.63      9752\n",
      "weighted avg       0.77      0.69      0.72      9752\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy: %s' % supervised_evaluation.accuracy_score(y_test, y_pred), end='\\n\\n')\n",
    "print('F1-score: %s' % supervised_evaluation.f1_score(y_test, y_pred, average=None), end='\\n\\n')\n",
    "print('Weighted Average F1-score: %s' % supervised_evaluation.f1_score(y_test, y_pred, average='weighted'), end='\\n\\n')\n",
    "print(supervised_evaluation.classification_report(y_test, y_pred), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9752/9752 [==============================] - 1s 69us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7772338813690983, 0.6910377144813538]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
