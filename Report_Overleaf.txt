\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{fancyhdr} %per personalizzare l'intestazione
\usepackage[italian]{babel}
\usepackage{tabularx}
\usepackage{lscape}
\usepackage[title]{appendix}
\usepackage{rotating}
\usepackage[margin=2.0cm]{geometry}
\usepackage{natbib}
\usepackage[T1]{fontenc}
\usepackage{wrapfig} %immagine all'interno del testo
\graphicspath{ {figures/} }
\usepackage{graphicx}
\usepackage{float}
\usepackage{chngcntr}
\usepackage{amsmath}
\addtolength{\topmargin}{-1cm}
\addtolength{\textheight}{1.1cm}

\pagenumbering{roman} %pagine iniziali con numeri romani


\title{Report Data Mining II}
\author{Ferri Lorenzo (607828) \\ email \href{mailto:lorenzoferri1995@gmail.com}{lorenzoferri1995@gmail.com} \and Pappolla Roberta (534109) \\ email
 \href{mailto:r.pappolla@studenti.unipi.it}{r.pappolla@studenti.unipi.it} \and Ema Ilic (602796) \\ email \href{mailto:e.ilic@studenti.unipi.it}{e.ilic@studenti.unipi.it}}
\date{Data Mining (654AA), Anno accademico 2019/2020}

\begin{document}
\maketitle
\newpage
\tableofcontents

\newpage
\listoffigures
\listoftables
\newpage

\pagenumbering{arabic} %conversione in numeri arabi


\section{Task 1}

\subsection{Data Understanding and Preparation}

Il Training Set fornito è costituito da 8143 Oggetti e 7 Attributi. 'Occupancy' è l'attributo binario in output su cui deve essere eseguita la classificazione, che riguarda la previsione della presenza o meno di un soggetto in una stanza. 'Date' è il momento temporale in cui vengono rilevati i valori dei restanti attributi, che sono tutti numerici. La serie temporale riguarda 6 giorni, dal 2015-02-04 alle 17:51:00 al 2015-02-10 alle 09:33:00, con una frequenza di rilevazione di un minuto. Il dataset non presenta alcun Missing Value e gli unici Null Values presenti sono 5160 valori dell'attributo 'Light'. Questi non sembrano costituire un errore di rilevazione perché sono coerenti con il significato dell'attributo (luce nulla quando la stanza è chiusa e inutilizzata o nelle ore notturne). Tutti gli attributi numerici presentano un picco di frequenze sulla parte bassa dei valori, caratteristica questa che è decisamente accentuata negli attributi 'Light' e 'CO2'. E' possibile che 0 e 450 circa siano rispettivamente i valori di 'Light' e 'CO2' nella stanza quando nessuno è presente. Valori diversi invece potrebbero indicare una certa attività nella stanza. Tale ipotesi è avvalorata dai Box Plot dei due attributi con valori raggruppati per classe in output. Le due mediane dei valori di 'Light'e 'CO2' quando 'Occupancy' è 1 sono rispettivamente 450 e 950 circa, molto diversi dai picchi in distribuzione.

\begin{figure}[H] \centering
\includegraphics[width=7cm]{Light Histogram.png}
\includegraphics[width=6cm]{Light Boxplot by Occupancy.png}

\includegraphics[width=7cm]{CO2 Densities.png}
\includegraphics[width=6cm]{CO2 Boxplot by Occupancy.png}

\caption{\label{fig:frog1}Distribuzioni e Box Plot 'Light', 'CO2'}
\end{figure}

\begin{wrapfigure}[10]{r}{0.5\textwidth}
\includegraphics[width=7cm]{Light vs Temperature Scatterplot.png}
\end{wrapfigure}

\noindent Sono stati riprodotti gli Scatter Plot di ciascuna coppia di attributi numerici. I due attributi con la maggior dipendenza lineare sono ovviamente risultati 'Humidity' ed 'Humidity Ratio'. Di fatto i due attributi esprimono lo stesso concetto, l'umidità, in due formati diversi (assoluta e relativa). Sebbene fosse possibile decidere di eliminare uno di essi ciò non è stato fatto perché la complessità del dataset non è un problema. Da un primo elementare approccio grafico l'unico attributo che riesce a discriminare bene tra le classi in output è 'Light'. L'attributo che ha mostrato la correlazione più elevata con 'Light' è stato 'Temperature': Pearson Corr = 0.65, Spearman Corr = 0.565, Kendall Corr = 0.415.


\subsection{Basic Classification Methods}

Lo scopo di questi modelli non è classificare una Time Series, quindi l'attributo relativo al tempo, 'date', è stato eliminato. Nei modelli in cui risultasse necessario sono stati cercati i migliori Iper-Parametri mediante una Random Search che ottimizzasse il Positive F1 Score medio che esce dalle 5 iterazioni compiute dalla Cross-Validation sul Training Set (Random Search CV con 5 Fold). La decisione dell'F1 come metrica da ottimizzare deriva dalla maggior attenzione riservata alle performance in termini di Precision e Recall per la classe 1 in output. I Decision Boundary sono stati rappresentati fittando il modello sulle due dimensioni rappresentate (non rappresenta dunque il reale Boundary su tutto il dataset ma ne fornisce un'approssimazione).
\\

\noindent \textbf{Decision Tree}: La Random Search CV è stata eseguita più volte cercando la combinazione più efficace degli Iper-Parametri 'min samples split' e 'min samples leaf' in un dominio molto ampio per entrambi [1, 500]. Le performance migliori si hanno per valori alti degli Iper-Parametri, che portano ad alberi semplici. L'albero migliore è uno split sull'attributo 'Light' al valore 365.125: le istanze classificate positive sono quelle con 'Light' > 365.125. L'attributo 'Light' quindi riveste un'importanza totale nella classificazione.

\begin{figure}[H] \centering
\includegraphics[width=7cm]{Decision Tree Plot.png}
\includegraphics[width=10cm]{Decision Boundary Decision Tree CO2 vs Light.png}

\caption{\label{fig:frog1}Decision Tree Results}
\end{figure}

\noindent Gli oggetti misclassificati sul Training Set sono solo 99 (di cui 90 sulla classe positiva). La 5 Fold Cross-Validation sul Training Set ha restituito: Accuracy con confidenza del 95\% = 0.98 (+/- 0.05); F1 Score medio pesato con confidenza del 95\% = 0.98 (+/- 0.04). Un singolo Decision Boundary lineare è sufficiente a discriminare bene nelle classi in output, gli errori non sono aree densamente popolate. E' stato appurato che modelli più complessi risultano overfittati sul Training Set e non performano bene sui Test Set.

\begin{center}
\begin{tabular}{ | m{13em} | m{3cm}| m{3cm} | } 
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
Accuracy: & 0.9786 & 0.9931 \\
\hline \centering
F1-score: & [0.9829, 0.9714] & [0.9956, 0.9838] \\ 
\hline \centering
Weighted Avg F1-score: & 0.9787 & 0.9931 \\ 
\hline \centering
Precision: & [1.00, 0.95] &  [1.00, 0.97] \\
\hline \centering
Recall: & [0.97, 1.00] & [0.99, 0.99] \\
\hline
\end{tabular}
\end{center}

\noindent L'AUC (Area sotto la ROC Curve) per i due Test Set è 0.983 e 0.994 rispettivamente. \newline
L'ipotesi formulata inizialmente in fase di Data Understanding per l'attributo 'Light' sembra essere confermata. Esso è sufficiente a predire la classe in output, con un semplice split che divide i casi in cui la stanza è lievemente o per niente illuminata ('Light' <= 365.125), caso tipico di assenza di persone all'interno, dai casi in cui la stanza è apprezzabilmente illuminata, perché ad esempio le finestre sono state aperte o è stata accesa la luce da qualcuno. Nel Training Set sono presenti 5160 oggetti con valore dell'attributo 'Light' pari a 0, tutti questi hanno valore della classe 'Occupancy' pari a 0.
\\

\noindent\textbf{K-NN}: Poiché il modello si basa sul calcolo delle distanze tra gli oggetti sia il Training che il Test Set sono stati Standardizzati (gli attributi sono stati riportati tutti a media 0 e varianza 1). La Random Search è stata eseguita cercando i migliori valori del numero di punti nelle vicinanze degli oggetti da classificare, nel dominio [1, 50], e del peso da dare a questi punti per classificare l'istanza. La miglior combinazione di Iper-Parametri è 'weights': 'uniform', 'n neighbors': 46. 

\begin{figure}[H] \centering
\includegraphics[width=7cm]{Feature Importance K-NN.png}
\includegraphics[width=10cm]{Decision Boundary K-NN CO2 vs Light.png}
\end{figure}

\noindent L'attributo più importante è sempre 'Light' ma anche 'CO2' riveste una seppur minima importanza. La Cross-Validation sul Training Set ha restituito una performance peggiore di quella del Decision Tree: Accuracy con confidenza del 95\% = 0.95 (+/- 0.08); F1 Score medio pesato con confidenza del 95\% = 0.95 (+/- 0.07). Anche la performance sui Test Set è peggiore, quindi 'CO2' in realtà non aggiunge significatività al modello.

\begin{center}
\begin{tabular}{ | m{13em} | m{3cm}| m{3cm} | } 
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
Accuracy: & 0.9595 & 0.956 \\
\hline \centering
F1-score: & [0.9684, 0.9434] & [0.9721, 0.8957] \\ 
\hline \centering
Weighted Avg F1-score: & 0.9593 & 0.9561 \\ 
\hline \centering
Precision: & [0.96, 0.96] &  [0.97, 0.89] \\
\hline \centering
Recall: & [0.98, 0.93] & [0.97, 0.90] \\
\hline
\end{tabular}
\end{center}

\noindent L'AUC delle ROC Curve è rispettivamente 0.99 e 0.988 per i due Test Set
\\

\noindent\textbf{Naive Bayes}: Non è necessario il Tuning di nessun iper-parametro. Le performances del modello sono analoghe a quelle del K-NN.

\begin{wrapfigure}[10]{r}{0.5\textwidth}
\includegraphics[width=10cm]{Decision Boundary Naive Bayes CO2 vs Light.png}
\end{wrapfigure}

\noindent Oltre a 'Light' anche la 'CO2' riveste una minima importanza e di nuovo le performance in termini di Cross-Validation sul Training Set e di test sul Test Set sono lievemente peggiori del Decision Tree banale. Solo l'area sotto le ROC Curve è maggiore. Questo significa che usando il 50\% come threshold di probabilità per la classificazione il modello ha una performance peggiore ma in genere risulta più stabile del Decision Tree perché è migliore se facciamo variare il threshold.
\\ \\

\begin{center}
\begin{tabular}{ | m{13em} | m{3cm}| m{3cm} | } 
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
Accuracy: & 0.9774 & 0.9876 \\
\hline \centering
F1-score: & [0.9820, 0.9699] & [0.9921, 0.9711] \\ 
\hline \centering
Weighted Avg F1-score: & 0.9776 & 0.9876 \\ 
\hline \centering
Precision: & [1.00, 0.95] &  [1.00, 0.95] \\
\hline \centering
Recall: & [0.97, 0.99] & [0.99, 0.99] \\
\hline
\end{tabular}
\end{center}

\begin{figure}[H] \centering
\includegraphics[width=7cm]{ROC Curve Test 1 Naive Bayes.png}
\includegraphics[width=7cm]{ROC Curve Test 2 Naive Bayes.png}
\caption{\label{fig:frog1}Naive Bayes Test on Test Set 1 and Test Set 2}
\end{figure}


\noindent\textbf{Logistic Regression}: Non è necessario il Tuning di nessun iper-parametro. Il modello ottenuto è il seguente:

\begin{equation}
P = \frac{1}{1 + \text{exp}(19.32 - 1.4 * \text{Temp} - 0.04 * \text{Humid} + 0.02 * \text{Light} + 0.01 * \text{CO2} - 0.1 * \text{HumidRatio})}
\end{equation}

\noindent Si assiste ad un incremento ulteriore dell'importanza della CO2 e ad una minima importanza anche dell'attributo 'Temperature'. 


\begin{figure}[H] \centering
\includegraphics[width=7cm]{Feature Importance Logistic Regression.png}
\includegraphics[width=10cm]{Decision Boundary Logistic Regression CO2 vs Light.png}
\caption{\label{fig:frog1}Decision Tree Validation}
\end{figure}

\noindent La Cross-Validation sul Training Set ha restituito valori leggermente migliori del Decision Tree, perché la varianza è minore: Accuracy con confidenza del 95\%: 0.98 (+/- 0.03); F1 Score medio pesato con confidenza del 95\%: 0.98 (+/- 0.03). Le performance sui Test Set sono ancora leggermente peggiori del Decision Tree. L'AUC è risultata la più alta di tutti i modelli, rendendo di fatto la Logistic Regression il modello più stabile.

\begin{center}
\begin{tabular}{ | m{13em} | m{3cm}| m{3cm} | } 
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
Accuracy: & 0.9764 & 0.9842 \\
\hline \centering
F1-score: & [0.9811, 0.9683] & [0.9900, 0.9619] \\ 
\hline \centering
Weighted Avg F1-score: & 0.9765 & 0.9841 \\ 
\hline \centering
Precision: & [0.99, 0.95] &  [0.99, 0.97] \\
\hline \centering
Recall: & [0.97, 0.99] & [0.99, 0.95] \\
\hline
\end{tabular}
\end{center}

\begin{figure}[H] \centering
\includegraphics[width=7cm]{ROC Curve Test 1 Logistic Regression.png}
\includegraphics[width=7cm]{ROC Curve Test 2 Logistic Regression.png}
\caption{\label{fig:frog1}Logistic Regression Test on Test Set 1 and Test Set 2}
\end{figure}

\noindent La regressione logistica è stata calibrata e testata anche con il solo attributo 'Light' in input. Il modello ottenuto è il seguente:

\begin{tabular}{ m{20em} m{3cm} }
\begin{equation}
P = \frac{1}{1 + \text{exp}(0.025 - 8.752 * \text{Light})}
\end{equation}
&
\includegraphics[width=7cm]{Logistic Regression con 'Light'.png}
\end{tabular}

\noindent Le performance sui Test sono identiche a quelle del Decision Tree iniziale perché questo modello porta allo stesso Decision Boundary singolo.



\subsection{Regression}

Poiché 'Light' è risultato ampiamente l'attributo più importante è stato scelto per tentare di predirne i valori mediante le regressioni. E' stata calibrata una regressione lineare (in due dimensioni) con solo l'attributo 'Temperature' in input, che è quello risultato più correlato con 'Light' nella fase di Data Understanding. La regressione rappresentata è sul Test Set e sono stati eliminati gli oggetti con valore di 'Light' pari a 0 (solo graficamente, non neiìl calcolo dei risultati, per focalizzare l'attenzione sulla parte importante della relazione lineare).


\begin{tabular}{ m{20em} m{3cm} }
\begin{equation}
\text{Light} = -2447.03 + 124.47 * \text{Temp}
\end{equation}
&
\includegraphics[width=8cm]{Light vs Temperature Linear Regression.png}
\end{tabular}


\noindent La performance viene misurata con il Coefficiente di Determinazione, lo Scarto Quadratico Medio e lo Scarto Assoluto Medio su entrambi i Test Set.

\begin{center}
\begin{tabular}{ | m{3em} | m{2cm}| m{2cm} | } 
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
R2: & 0.512 & 0.444 \\
\hline \centering
MSE: & 30530.250 & 24109.752 \\ 
\hline \centering
MAE: & 152.073 & 131.116 \\ 
\hline
\end{tabular}
\end{center}

\noindent E' stata prodotta la regressione multipla aggiungendo tutti gli altri attributi numerici in input. Il modello è stato regolarizzato per tentare di ridurne la complessità, ponendo più vicini a zero i parametri che non migliorano sensibilmente la predizione dell'output. Il miglior risultato è stato raggiunto con la Ridge Regression, ma sul secondo Test Set la performance peggiora.

\begin{equation}
\text{Light} = -1176.14 + 0.35 * \text{CO2} -5.78  * \text{Humid} -15.83  * \text{HumidRatio} +59.83  * \text{Temp}
\end{equation}


\begin{center}
\begin{tabular}{ | m{3em} | m{2cm}| m{2cm} | }
\hline
& Test Set 1 & Test Set 2 \\
\hline\hline \centering
R2: & 0.595 & 0.153 \\
\hline \centering
MSE: & 25364.214 & 36724.966 \\ 
\hline \centering
MAE: & 131.360 & 148.516 \\ 
\hline
\end{tabular}
\end{center}


\subsection{Dimensionality Reduction with Decision Tree}


\subsection{Dimensionality Reduction with different classifiers}


\subsection{Imbalanced Learning}
 

\section{Task 2}

\subsection{Support Vector Machines (SVM)}

\subsection{Neural Networks and Deep Learning}


\subsection{Ensemble Learning}


\section{Task 3}

\subsection{Forecasting}


\section{Task 4}


\section{Task 5}


\end{document}
